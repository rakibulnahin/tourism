{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T13:02:52.020682Z",
     "iopub.status.busy": "2025-06-12T13:02:52.020048Z",
     "iopub.status.idle": "2025-06-12T13:02:52.025102Z",
     "shell.execute_reply": "2025-06-12T13:02:52.024412Z",
     "shell.execute_reply.started": "2025-06-12T13:02:52.020658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T14:19:02.461536Z",
     "iopub.status.busy": "2025-06-12T14:19:02.461055Z",
     "iopub.status.idle": "2025-06-12T14:20:34.760236Z",
     "shell.execute_reply": "2025-06-12T14:20:34.759218Z",
     "shell.execute_reply.started": "2025-06-12T14:19:02.461514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install accelerate peft bitsandbytes\n",
    "# %pip install -U flash-attn\n",
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T14:22:24.994535Z",
     "iopub.status.busy": "2025-06-12T14:22:24.994187Z",
     "iopub.status.idle": "2025-06-12T14:22:25.667661Z",
     "shell.execute_reply": "2025-06-12T14:22:25.667056Z",
     "shell.execute_reply.started": "2025-06-12T14:22:24.994507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hf_token = \"hf_token\"\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T13:03:29.286159Z",
     "iopub.status.busy": "2025-06-12T13:03:29.285886Z",
     "iopub.status.idle": "2025-06-12T13:03:50.976644Z",
     "shell.execute_reply": "2025-06-12T13:03:50.975780Z",
     "shell.execute_reply.started": "2025-06-12T13:03:29.286138Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 13:03:38.927316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749733419.126899      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749733419.182846      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/3798292389.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLoraConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_model_for_kbit_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFTTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSFTConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trl'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:24.339948Z",
     "iopub.status.busy": "2025-05-24T01:53:24.339039Z",
     "iopub.status.idle": "2025-05-24T01:53:24.354330Z",
     "shell.execute_reply": "2025-05-24T01:53:24.353635Z",
     "shell.execute_reply.started": "2025-05-24T01:53:24.339920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "# Model from Hugging Face hub\n",
    "base_model = \"meta-llama/Llama-2-7b-chat-hf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Simple Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:24.355666Z",
     "iopub.status.busy": "2025-05-24T01:53:24.355356Z",
     "iopub.status.idle": "2025-05-24T01:53:25.210975Z",
     "shell.execute_reply": "2025-05-24T01:53:25.210420Z",
     "shell.execute_reply.started": "2025-05-24T01:53:24.355640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_tokenizer = AutoTokenizer.from_pretrained(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:25.212184Z",
     "iopub.status.busy": "2025-05-24T01:53:25.211939Z",
     "iopub.status.idle": "2025-05-24T01:53:25.220761Z",
     "shell.execute_reply": "2025-05-24T01:53:25.219862Z",
     "shell.execute_reply.started": "2025-05-24T01:53:25.212162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   306,  5735,   297, 16198,  3865, 29956,   297,  8314, 29892,\n",
       "          2649,   592,   278,  7600,  2978, 19205,  3801,   541,   451,  2768,\n",
       "         19205,  3801,   988,   306,   508,   748,   363,   263,  2462, 17487,\n",
       "           773,   970,  8608]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = model_tokenizer(\"I live in Sydney NSW in Australia, tell me the places near sydney but not inside sydney where I can go for a day trip using public transport\"\n",
    "                  , return_tensors=\"pt\"\n",
    "                  ).to(device)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:25.221687Z",
     "iopub.status.busy": "2025-05-24T01:53:25.221488Z",
     "iopub.status.idle": "2025-05-24T01:53:25.237512Z",
     "shell.execute_reply": "2025-05-24T01:53:25.236848Z",
     "shell.execute_reply.started": "2025-05-24T01:53:25.221672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(base_model, torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:25.238349Z",
     "iopub.status.busy": "2025-05-24T01:53:25.238188Z",
     "iopub.status.idle": "2025-05-24T01:53:25.251681Z",
     "shell.execute_reply": "2025-05-24T01:53:25.251178Z",
     "shell.execute_reply.started": "2025-05-24T01:53:25.238335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     output_ids = model.generate(**inputs, top_k=10, do_sample=True)\n",
    "# # output_ids[0] is logits\n",
    "# generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:25.252506Z",
     "iopub.status.busy": "2025-05-24T01:53:25.252306Z",
     "iopub.status.idle": "2025-05-24T01:53:26.334723Z",
     "shell.execute_reply": "2025-05-24T01:53:26.334176Z",
     "shell.execute_reply.started": "2025-05-24T01:53:25.252491Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds1 = load_dataset(\"JasleenSingh91/travel-questions-response\")\n",
    "df1 = pd.DataFrame(ds1['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.335669Z",
     "iopub.status.busy": "2025-05-24T01:53:26.335443Z",
     "iopub.status.idle": "2025-05-24T01:53:26.341121Z",
     "shell.execute_reply": "2025-05-24T01:53:26.340156Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.335650Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommend solo adventure destinations in Africa, including safaris, hiking to volcanoes, and exploring ancient cultures.\n",
      "----------------------------------\n",
      "\n",
      "Absolutely! Africa is a wonderful continent for solo adventures, offering a diverse range of experiences from adventure safaris, mountain treks, to exploring ancient cultures. Here are some recommendations:\n",
      "1. Serengeti National Park, Tanzania: Known as the \"Greatest Wildlife Show on Earth,\" the Serengeti is a must-visit destination for solo travelers who love wildlife. Go on a safari to witness the annual Great Migration, where millions of animals migrate in search of water and fresh grazing lands. Stay at a tented camp or lodge for an authentic African experience.\n",
      "2. Mount Kilimanjaro, Tanzania: This is a once-in-a-lifetime adventure for solo travelers seeking a challenge. Mount Kilimanjaro is the highest peak in Africa and offers breathtaking views of the African landscape. Join a guided tour, hire a guide and porters, and tackle the summit.\n",
      "3. Gorilla Trekking in Rwanda or Uganda: For solo travelers interested in nature and wildlife, gorilla trekking is an unforgettable experience. Rwanda and Uganda offer affordable gorilla permits and guided tours to help you track these endangered primates.\n",
      "4. Petra, Jordan: Discover the ancient city of Petra, a UNESCO World Heritage Site. Explore the famous Treasury, the Monastery, and other ruins on foot. Petra is a popular tourist destination, but it can be easily explored solo with the help of a local guide.\n",
      "5. Marrakech, Morocco: Marrakech offers a rich cultural experience with its bustling markets, delicious food, and historic sites. Explore the Bahia Palace, the Jardin Majorelle, and the vibrant Jemaa El-Fnaa square. Marrakech\n",
      "----------------------------------\n",
      "\n",
      " Hello there! As a travel agent, I'd be delighted to recommend some exciting solo adventure destinations in Africa that cater to your interests. From safaris and volcano hiking to exploring ancient cultures, Africa has plenty to offer. Here are some unique experiences you might enjoy:\n",
      "\n",
      "1. Safaris in Maasai Mara, Kenya:\n",
      "Maasai Mara National Reserve is renowned for its abundant wildlife and the Mara River, which attracts countless hippos, crocodiles, and birds. Experience a thrilling safari adventure with expert guides who will give you an in-depth look into the lives of Africa's iconic species. Start your day with a hot air balloon ride over the savannah for breathtaking views. For a more immersive experience, choose a fly-and-camp safari package, allowing you to spend a night under the stars with your guides.\n",
      "\n",
      "Cost: $100-$500 per person per day\n",
      "Duration: 3-5 days\n",
      "Accommodation: Luxury safari camps or mid-range lodges\n",
      "\n",
      "2. Hiking Mount Nyiragongo, Democratic Republic of Congo:\n",
      "Mount Nyiragongo is a majestic volcano with a glowing lava lake at its base. Hike the 11-kilometer trail to the summit to witness the mesmerizing views and unique geological formations. The hike takes around 2-3 days and is considered moderate to challenging. Be prepared for stunning views of the surrounding landscape and the opportunity to spot unique flora and fauna.\n",
      "\n",
      "Cost: $500-$1,000 per person\n",
      "Duration: 2-3 days\n",
      "Accommodation: Basic camping facilities or basic lodges\n",
      "\n",
      "3. Discovery of Ancient Cultures in Ethiopia:\n",
      "Explore the ancient rock-hewn churches of Lalibela, a UNESCO World Heritage Site. The churches, built in the 12th century, are adorned with intricate carvings and mosaics. Visit the nearby Mount Senkelle Wildlife Sanctuary to see the elusive Gelada baboons. In the evenings, enjoy local cuisine and drink coffee with the\n"
     ]
    }
   ],
   "source": [
    "x = 4897\n",
    "print(df1.iloc[x][\"Input\"])\n",
    "print(\"----------------------------------\\n\")\n",
    "print(df1.iloc[x][\"Response_1\"])\n",
    "print(\"----------------------------------\\n\")\n",
    "print(df1.iloc[x][\"Response_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.342123Z",
     "iopub.status.busy": "2025-05-24T01:53:26.341829Z",
     "iopub.status.idle": "2025-05-24T01:53:26.359469Z",
     "shell.execute_reply": "2025-05-24T01:53:26.358918Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.342089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input         What activities and places should I explore in...\n",
       "Response_1    I'd be happy to help you plan an exciting and ...\n",
       "Response_2     Ahaha, I'd be thrilled to help you plan your ...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.360364Z",
     "iopub.status.busy": "2025-05-24T01:53:26.360181Z",
     "iopub.status.idle": "2025-05-24T01:53:26.421658Z",
     "shell.execute_reply": "2025-05-24T01:53:26.420934Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.360350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# making the system prompt text\n",
    "system_prompt = \"Can you please help me with.\"\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        system_msg = \"Please help me with \"\n",
    "        user_input = self.df.iloc[index][\"Input\"]\n",
    "        assistant_response = self.df.iloc[index][\"Response_1\"]\n",
    "        return f\"<s>[INST] <<SYS>>\\n{system_msg}\\n<</SYS>>\\n\\n{user_input} [/INST]{assistant_response} </s>\"\n",
    "\n",
    "def format_row(user_input, assistant_response, system_msg=system_prompt):\n",
    "    return f\"<s>[INST] <<SYS>>\\n{system_msg}\\n<</SYS>>\\n\\n{user_input} [/INST]{assistant_response} </s>\"\n",
    "\n",
    "df1[\"text\"] = df1.apply(lambda row: format_row(row[\"Input\"], row[\"Response_1\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.424721Z",
     "iopub.status.busy": "2025-05-24T01:53:26.424452Z",
     "iopub.status.idle": "2025-05-24T01:53:26.432812Z",
     "shell.execute_reply": "2025-05-24T01:53:26.432121Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.424703Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Response_1</th>\n",
       "      <th>Response_2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you suggest the best travel destinations f...</td>\n",
       "      <td>Absolutely! To help me suggest the best trave...</td>\n",
       "      <td>Hi there! I'd be delighted to help you plan y...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What activities and places should I explore in...</td>\n",
       "      <td>I'd be happy to help you plan an exciting and ...</td>\n",
       "      <td>Ahaha, I'd be thrilled to help you plan your ...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you recommend relaxing destinations to vis...</td>\n",
       "      <td>Absolutely! Winter can be a beautiful and pea...</td>\n",
       "      <td>As a travel agent, I'd be delighted to recomm...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the top winter vacation spots?</td>\n",
       "      <td>Absolutely! I'd be happy to help you plan your...</td>\n",
       "      <td>As a travel agent, I'm happy to share with yo...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can you recommend a great vacation destination...</td>\n",
       "      <td>Absolutely! Based on your preferences, I woul...</td>\n",
       "      <td>I'd love to help you plan an unforgettable va...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input  \\\n",
       "0  Can you suggest the best travel destinations f...   \n",
       "1  What activities and places should I explore in...   \n",
       "2  Can you recommend relaxing destinations to vis...   \n",
       "3            What are the top winter vacation spots?   \n",
       "4  Can you recommend a great vacation destination...   \n",
       "\n",
       "                                          Response_1  \\\n",
       "0   Absolutely! To help me suggest the best trave...   \n",
       "1  I'd be happy to help you plan an exciting and ...   \n",
       "2   Absolutely! Winter can be a beautiful and pea...   \n",
       "3  Absolutely! I'd be happy to help you plan your...   \n",
       "4   Absolutely! Based on your preferences, I woul...   \n",
       "\n",
       "                                          Response_2  \\\n",
       "0   Hi there! I'd be delighted to help you plan y...   \n",
       "1   Ahaha, I'd be thrilled to help you plan your ...   \n",
       "2   As a travel agent, I'd be delighted to recomm...   \n",
       "3   As a travel agent, I'm happy to share with yo...   \n",
       "4   I'd love to help you plan an unforgettable va...   \n",
       "\n",
       "                                                text  \n",
       "0  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "1  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "2  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "3  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "4  <s>[INST] <<SYS>>\\nCan you please help me with...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.433724Z",
     "iopub.status.busy": "2025-05-24T01:53:26.433519Z",
     "iopub.status.idle": "2025-05-24T01:53:26.451860Z",
     "shell.execute_reply": "2025-05-24T01:53:26.451300Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.433708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_set, eval_set = train_test_split(df1, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.452762Z",
     "iopub.status.busy": "2025-05-24T01:53:26.452564Z",
     "iopub.status.idle": "2025-05-24T01:53:26.467407Z",
     "shell.execute_reply": "2025-05-24T01:53:26.466665Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.452746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4807, 4)\n",
      "(1202, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_set.shape)\n",
    "print(eval_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.468577Z",
     "iopub.status.busy": "2025-05-24T01:53:26.468132Z",
     "iopub.status.idle": "2025-05-24T01:53:26.486160Z",
     "shell.execute_reply": "2025-05-24T01:53:26.485605Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.468550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Response_1</th>\n",
       "      <th>Response_2</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>Suggest a winter hiking destination with stunn...</td>\n",
       "      <td>I'd recommend Lake Tahoe in California and Ne...</td>\n",
       "      <td>A fantastic winter hiking destination with st...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>Suggest a budget-friendly mountain Airbnb with...</td>\n",
       "      <td>Instruction: I'd be happy to help you find a b...</td>\n",
       "      <td>Ah, I've got just the thing for you!\\n\\nI rec...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>Recommend budget-friendly mountain resorts for...</td>\n",
       "      <td>I'd be happy to help you find some budget-fri...</td>\n",
       "      <td>Ahaha, I'm excited to help you plan your next...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>Recommend solo travel destinations for explori...</td>\n",
       "      <td>Subject: Exciting Solo Cave Exploring Adventur...</td>\n",
       "      <td>Ah, an adventure-seeking solo traveler, eh? N...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303</th>\n",
       "      <td>Plan a fall trip to a destination known for it...</td>\n",
       "      <td>Destination: Vermont, USA\\n\\nOverview:\\nVermon...</td>\n",
       "      <td>Fall is indeed a wonderful time to travel, wi...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>Recommend travel destinations offering both re...</td>\n",
       "      <td>Absolutely! I'd be happy to help you plan a va...</td>\n",
       "      <td>As a travel agent, I'm excited to recommend t...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Recommend solo travel destinations in India of...</td>\n",
       "      <td>Absolutely, I'd be happy to help you plan a sp...</td>\n",
       "      <td>Ah, thank you for considering India, a countr...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>Suggest the best family vacation spots in Ital...</td>\n",
       "      <td>Italy is a wonderful destination for families ...</td>\n",
       "      <td>Italy - the land of love, art, history, and d...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Recommend solo travel destinations in Greece f...</td>\n",
       "      <td>Absolutely, I'd be happy to help you plan a so...</td>\n",
       "      <td>Welcome! As a travel agent, I'm thrilled to s...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>What are the best fall destinations for vibran...</td>\n",
       "      <td>Absolutely, I'd be happy to help you plan a f...</td>\n",
       "      <td>Ah, autumn is one of my favorite seasons! I'v...</td>\n",
       "      <td>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nCan you please help me with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4807 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input  \\\n",
       "5634  Suggest a winter hiking destination with stunn...   \n",
       "4434  Suggest a budget-friendly mountain Airbnb with...   \n",
       "2350  Recommend budget-friendly mountain resorts for...   \n",
       "5414  Recommend solo travel destinations for explori...   \n",
       "3303  Plan a fall trip to a destination known for it...   \n",
       "...                                                 ...   \n",
       "3772  Recommend travel destinations offering both re...   \n",
       "5191  Recommend solo travel destinations in India of...   \n",
       "5226  Suggest the best family vacation spots in Ital...   \n",
       "5390  Recommend solo travel destinations in Greece f...   \n",
       "860   What are the best fall destinations for vibran...   \n",
       "\n",
       "                                             Response_1  \\\n",
       "5634   I'd recommend Lake Tahoe in California and Ne...   \n",
       "4434  Instruction: I'd be happy to help you find a b...   \n",
       "2350   I'd be happy to help you find some budget-fri...   \n",
       "5414  Subject: Exciting Solo Cave Exploring Adventur...   \n",
       "3303  Destination: Vermont, USA\\n\\nOverview:\\nVermon...   \n",
       "...                                                 ...   \n",
       "3772  Absolutely! I'd be happy to help you plan a va...   \n",
       "5191  Absolutely, I'd be happy to help you plan a sp...   \n",
       "5226  Italy is a wonderful destination for families ...   \n",
       "5390  Absolutely, I'd be happy to help you plan a so...   \n",
       "860    Absolutely, I'd be happy to help you plan a f...   \n",
       "\n",
       "                                             Response_2  \\\n",
       "5634   A fantastic winter hiking destination with st...   \n",
       "4434   Ah, I've got just the thing for you!\\n\\nI rec...   \n",
       "2350   Ahaha, I'm excited to help you plan your next...   \n",
       "5414   Ah, an adventure-seeking solo traveler, eh? N...   \n",
       "3303   Fall is indeed a wonderful time to travel, wi...   \n",
       "...                                                 ...   \n",
       "3772   As a travel agent, I'm excited to recommend t...   \n",
       "5191   Ah, thank you for considering India, a countr...   \n",
       "5226   Italy - the land of love, art, history, and d...   \n",
       "5390   Welcome! As a travel agent, I'm thrilled to s...   \n",
       "860    Ah, autumn is one of my favorite seasons! I'v...   \n",
       "\n",
       "                                                   text  \n",
       "5634  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "4434  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "2350  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "5414  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "3303  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "...                                                 ...  \n",
       "3772  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "5191  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "5226  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "5390  <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "860   <s>[INST] <<SYS>>\\nCan you please help me with...  \n",
       "\n",
       "[4807 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.487089Z",
     "iopub.status.busy": "2025-05-24T01:53:26.486777Z",
     "iopub.status.idle": "2025-05-24T01:53:26.580130Z",
     "shell.execute_reply": "2025-05-24T01:53:26.579550Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.487072Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_set = MyDataset(train_set)\n",
    "# eval_set = MyDataset(eval_set)\n",
    "\n",
    "train_set = Dataset.from_pandas(train_set[[\"text\"]])\n",
    "eval_set = Dataset.from_pandas(eval_set[[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.581035Z",
     "iopub.status.busy": "2025-05-24T01:53:26.580808Z",
     "iopub.status.idle": "2025-05-24T01:53:26.586024Z",
     "shell.execute_reply": "2025-05-24T01:53:26.585301Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.581018Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"<s>[INST] <<SYS>>\\nCan you please help me with.\\n<</SYS>>\\n\\nSuggest a winter hiking destination with stunning landscapes and challenging trails. [/INST] I'd recommend Lake Tahoe in California and Nevada as a winter hiking destination. Known for its breathtaking landscapes, Lake Tahoe offers some of the most challenging and rewarding hikes during the winter months.\\n\\nPopular Trails:\\n1. Cascade Falls Trail: A moderately difficult trail, featuring a stunning frozen waterfall and beautiful views of Lake Tahoe. (Approx. 5 Miles Roundtrip)\\n2. Eagle Falls Trail: This challenging hike to Eagle Falls requires some ice axe and crampons usage, making it perfect for experienced hikers looking for a true winter adventure. (Approx. 5 Miles Roundtrip)\\n3. Gladys Lake Trail: The trail leads to a picturesque lake that's surrounded by snowy peaks and frozen trees. Though the trail is challenging, the reward is worth the effort. (Approx. 7 Miles Roundtrip)\\n\\nWeather Conditions: Winter temperatures typically range from 20°F (-6°C) to 40°F (4°C). Be prepared for snow and ice on the trails and pack appropriate hiking gear, including microspikes or crampons, a pair of gaiters, and trekking poles.\\n\\nAdditional Tips:\\n1. Always check weather conditions and road closures before embarking on your hike.\\n2. Bring plenty of water and high-energy snacks for the journey.\\n3. Be aware of avalanche risks and potential hazards and stay informed about the location and status of any known hazards.\\n4. Let someone know your hiking plans and intended route before you leave, along with an expected return time.\\n5. Dress in layers to help regulate your body temperature while hiking.\\n6. Carry a map, compass, and GPS, and </s>\",\n",
       " '__index_level_0__': 5634}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup with LoRa 4 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:53:26.587102Z",
     "iopub.status.busy": "2025-05-24T01:53:26.586811Z",
     "iopub.status.idle": "2025-05-24T01:54:32.134591Z",
     "shell.execute_reply": "2025-05-24T01:54:32.134056Z",
     "shell.execute_reply.started": "2025-05-24T01:53:26.587079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1b3375edbd47889aa8bbf73eddd1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=None\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=quant_config,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:54:32.135570Z",
     "iopub.status.busy": "2025-05-24T01:54:32.135319Z",
     "iopub.status.idle": "2025-05-24T01:54:32.143794Z",
     "shell.execute_reply": "2025-05-24T01:54:32.143200Z",
     "shell.execute_reply.started": "2025-05-24T01:54:32.135552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T08:27:59.924633Z",
     "iopub.status.busy": "2025-05-24T08:27:59.924051Z",
     "iopub.status.idle": "2025-05-24T08:27:59.977254Z",
     "shell.execute_reply": "2025-05-24T08:27:59.976497Z",
     "shell.execute_reply.started": "2025-05-24T08:27:59.924611Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_params = SFTConfig(\n",
    "    output_dir=\"/kaggle/working/output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    max_length = 500,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T08:28:00.126375Z",
     "iopub.status.busy": "2025-05-24T08:28:00.126150Z",
     "iopub.status.idle": "2025-05-24T08:28:08.866436Z",
     "shell.execute_reply": "2025-05-24T08:28:08.865860Z",
     "shell.execute_reply.started": "2025-05-24T08:28:00.126357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e3c29ea63e4cbcb5b25eb6b56c00ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/4807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced49978acb54c8e848f709a575c344d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/4807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11cfc5a31674f2b852a7ddbb3e1edd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/4807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d5256061674819a06f11bf999e3148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/4807 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca986d7edd384462a1bfa08ca345e10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/1202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1947c4dcd3d48769111efef7f711991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/1202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e69b5fa68843df84c5c51efb3a64a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/1202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6c03c64f214a7eadf666c1630950c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/1202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=eval_set,\n",
    "    peft_config=peft_params,\n",
    "    args=training_params,\n",
    "    # max_length =1000,\n",
    "    # packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T01:54:40.748540Z",
     "iopub.status.busy": "2025-05-24T01:54:40.748276Z",
     "iopub.status.idle": "2025-05-24T05:14:26.612125Z",
     "shell.execute_reply": "2025-05-24T05:14:26.611546Z",
     "shell.execute_reply.started": "2025-05-24T01:54:40.748516Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  11995 MiB |  12117 MiB |  33272 GiB |  33261 GiB |\n",
      "|       from large pool |  11351 MiB |  11601 MiB |  33241 GiB |  33230 GiB |\n",
      "|       from small pool |    644 MiB |    644 MiB |     30 GiB |     30 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  11995 MiB |  12117 MiB |  33272 GiB |  33261 GiB |\n",
      "|       from large pool |  11351 MiB |  11601 MiB |  33241 GiB |  33230 GiB |\n",
      "|       from small pool |    644 MiB |    644 MiB |     30 GiB |     30 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |  11965 MiB |  12087 MiB |  33271 GiB |  33259 GiB |\n",
      "|       from large pool |  11321 MiB |  11571 MiB |  33240 GiB |  33229 GiB |\n",
      "|       from small pool |    644 MiB |    644 MiB |     30 GiB |     30 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  13090 MiB |  14560 MiB |  15052 MiB |   1962 MiB |\n",
      "|       from large pool |  12442 MiB |  13912 MiB |  14402 MiB |   1960 MiB |\n",
      "|       from small pool |    648 MiB |    648 MiB |    650 MiB |      2 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   1094 MiB |   6179 MiB |  22481 GiB |  22480 GiB |\n",
      "|       from large pool |   1090 MiB |   6178 MiB |  22447 GiB |  22446 GiB |\n",
      "|       from small pool |      3 MiB |      6 MiB |     33 GiB |     33 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1965    |    1965    |  581105    |  579140    |\n",
      "|       from large pool |     681    |     683    |  482922    |  482241    |\n",
      "|       from small pool |    1284    |    1284    |   98183    |   96899    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1965    |    1965    |  581105    |  579140    |\n",
      "|       from large pool |     681    |     683    |  482922    |  482241    |\n",
      "|       from small pool |    1284    |    1284    |   98183    |   96899    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     356    |     359    |     361    |       5    |\n",
      "|       from large pool |      32    |      35    |      36    |       4    |\n",
      "|       from small pool |     324    |     324    |     325    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     162    |     163    |  281767    |  281605    |\n",
      "|       from large pool |      94    |      95    |  253119    |  253025    |\n",
      "|       from small pool |      68    |      83    |   28648    |   28580    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 3:16:44, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.832400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.777100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75, training_loss=0.9155764770507813, metrics={'train_runtime': 11983.5164, 'train_samples_per_second': 0.401, 'train_steps_per_second': 0.006, 'total_flos': 8.560893240764006e+16, 'train_loss': 0.9155764770507813})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T05:14:26.613094Z",
     "iopub.status.busy": "2025-05-24T05:14:26.612837Z",
     "iopub.status.idle": "2025-05-24T05:14:39.202233Z",
     "shell.execute_reply": "2025-05-24T05:14:39.201420Z",
     "shell.execute_reply.started": "2025-05-24T05:14:26.613077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T05:36:01.359571Z",
     "iopub.status.busy": "2025-05-24T05:36:01.359291Z",
     "iopub.status.idle": "2025-05-24T05:36:01.416096Z",
     "shell.execute_reply": "2025-05-24T05:36:01.415197Z",
     "shell.execute_reply.started": "2025-05-24T05:36:01.359550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/tokenizer/tokenizer_config.json',\n",
       " '/kaggle/working/tokenizer/special_tokens_map.json',\n",
       " '/kaggle/working/tokenizer/tokenizer.model',\n",
       " '/kaggle/working/tokenizer/added_tokens.json',\n",
       " '/kaggle/working/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tokenizer.save_pretrained(\"/kaggle/working/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T05:35:26.244551Z",
     "iopub.status.busy": "2025-05-24T05:35:26.243768Z",
     "iopub.status.idle": "2025-05-24T05:35:26.641099Z",
     "shell.execute_reply": "2025-05-24T05:35:26.640371Z",
     "shell.execute_reply.started": "2025-05-24T05:35:26.244525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# !mkdir output\n",
    "# !mkdir tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T05:14:39.208870Z",
     "iopub.status.busy": "2025-05-24T05:14:39.208546Z",
     "iopub.status.idle": "2025-05-24T05:14:55.585725Z",
     "shell.execute_reply": "2025-05-24T05:14:55.584995Z",
     "shell.execute_reply.started": "2025-05-24T05:14:39.208845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T05:36:31.802657Z",
     "iopub.status.busy": "2025-05-24T05:36:31.802324Z",
     "iopub.status.idle": "2025-05-24T05:36:32.337407Z",
     "shell.execute_reply": "2025-05-24T05:36:32.336649Z",
     "shell.execute_reply.started": "2025-05-24T05:36:31.802633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/tokenizer/ (stored 0%)\n",
      "  adding: kaggle/working/tokenizer/special_tokens_map.json (deflated 74%)\n",
      "  adding: kaggle/working/tokenizer/tokenizer.json (deflated 85%)\n",
      "  adding: kaggle/working/tokenizer/tokenizer.model (deflated 55%)\n",
      "  adding: kaggle/working/tokenizer/tokenizer_config.json (deflated 66%)\n"
     ]
    }
   ],
   "source": [
    "# !zip -r /kaggle/working/tokenizer.zip /kaggle/working/tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T08:39:02.843760Z",
     "iopub.status.busy": "2025-05-24T08:39:02.843469Z",
     "iopub.status.idle": "2025-05-24T08:39:11.580297Z",
     "shell.execute_reply": "2025-05-24T08:39:11.579544Z",
     "shell.execute_reply.started": "2025-05-24T08:39:02.843740Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353a6d5a6b3c4525aec79c98a06b3e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "optimizer.pt:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fc5b5ee7f2489eb3a531c43975dcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler.pt:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e40e423e9e43018084420560956cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e5d813b84544539f1bd793ef5e7569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3925664839141acb9014d47a33df734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rng_state.pth:   0%|          | 0.00/14.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d2eec1b48e4a6db95742acda310931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42849d0e1e2640db8e65170d3361f7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/rakibulnahin/travel-chat-llama2-7b-lora-4bit-finetuned/commit/2e00c8bed9dcb2ae9368e1e73bb3f7628880928a', commit_message='Upload folder using huggingface_hub', commit_description='', oid='2e00c8bed9dcb2ae9368e1e73bb3f7628880928a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/rakibulnahin/travel-chat-llama2-7b-lora-4bit-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='rakibulnahin/travel-chat-llama2-7b-lora-4bit-finetuned'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "repo_id=\"rakibulnahin/travel-chat-llama2-7b-lora-4bit-finetuned\"\n",
    "create_repo(repo_id, private=False)\n",
    "upload_folder(\n",
    "    repo_id=repo_id,\n",
    "    folder_path=\"/kaggle/working/output/checkpoint-75\",\n",
    "    path_in_repo=\".\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferencing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T14:43:29.733851Z",
     "iopub.status.busy": "2025-06-12T14:43:29.733611Z",
     "iopub.status.idle": "2025-06-12T14:43:29.737459Z",
     "shell.execute_reply": "2025-06-12T14:43:29.736710Z",
     "shell.execute_reply.started": "2025-06-12T14:43:29.733836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:00:28.355128Z",
     "iopub.status.busy": "2025-06-12T15:00:28.354678Z",
     "iopub.status.idle": "2025-06-12T15:00:29.512594Z",
     "shell.execute_reply": "2025-06-12T15:00:29.512002Z",
     "shell.execute_reply.started": "2025-06-12T15:00:28.355103Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "del model  # or any large tensors/models\n",
    "del base_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:00:32.845290Z",
     "iopub.status.busy": "2025-06-12T15:00:32.844630Z",
     "iopub.status.idle": "2025-06-12T15:01:06.282799Z",
     "shell.execute_reply": "2025-06-12T15:01:06.282030Z",
     "shell.execute_reply.started": "2025-06-12T15:00:32.845265Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b64aea623bb49a89f2e6dc30e35e60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # or torch.bfloat16 on newer GPUs\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:01:11.940106Z",
     "iopub.status.busy": "2025-06-12T15:01:11.939820Z",
     "iopub.status.idle": "2025-06-12T15:01:12.812662Z",
     "shell.execute_reply": "2025-06-12T15:01:12.812100Z",
     "shell.execute_reply.started": "2025-06-12T15:01:11.940087Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from peft import PeftModel\n",
    "# from transformers import AutoModelForCausalLM\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\").to(device)\n",
    "model = PeftModel.from_pretrained(base_model, \"rakibulnahin/travel-chat-llama2-7b-lora-4bit-finetuned\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:01:16.733545Z",
     "iopub.status.busy": "2025-06-12T15:01:16.733275Z",
     "iopub.status.idle": "2025-06-12T15:01:17.005148Z",
     "shell.execute_reply": "2025-06-12T15:01:17.004574Z",
     "shell.execute_reply.started": "2025-06-12T15:01:16.733526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer2 = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T15:01:28.350811Z",
     "iopub.status.busy": "2025-06-12T15:01:28.350549Z",
     "iopub.status.idle": "2025-06-12T15:02:13.786847Z",
     "shell.execute_reply": "2025-06-12T15:02:13.786040Z",
     "shell.execute_reply.started": "2025-06-12T15:01:28.350793Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make a travel plan for a exciting experience in Vietnam with friends including various activites and relaxing experience.\n",
      "Title: Adventure-Filled Vietnam Excursion with Friends\n",
      "Destination: Vietnam\n",
      "Duration: 10 days\n",
      "Purpose: To explore Vietnam's diverse culture, history, and natural beauty while enjoying various activities and relaxation experiences with friends.\n",
      "Day 1: Arrival in Hanoi\n",
      "* Arrive at Noi Bai International Airport in Hanoi and check into the hotel.\n",
      "* Spend the day exploring the Old Quarter and Hoan Kiem Lake.\n",
      "* Enjoy dinner at a local restaurant.\n",
      "\n",
      "Day 2: Hanoi City Tour\n",
      "* Visit the Temple of Literature, Ngoc Son Temple, and the Museum of Ethnology.\n",
      "* Take a traditional cyclo tour of the city.\n",
      "* Enjoy lunch at a local street food market.\n",
      "\n",
      "Day 3: Ha Long Bay Day Trip\n",
      "* Take an early morning bus to Halong Bay.\n",
      "* Board a luxury cruise ship and spend the day exploring the bay's stunning limestone islands, caves, and waterfalls.\n",
      "* Enjoy dinner onboard and overnight stay.\n",
      "\n",
      "Day 4: Hoi An\n",
      "* Fly from Hanoi to Danang and then take a taxi or train to Hoi An.\n",
      "* Check into the hotel and spend the afternoon exploring this charming ancient town.\n",
      "* Enjoy dinner at a local seafood restaurant.\n",
      "\n",
      "Day 5: Hoi An and Beach Relaxation\n",
      "* Spend the day relaxing on the beach or exploring nearby attractions such as the Marble Mountains and Cham Island.\n",
      "* Enjoy a massage or spa treatment.\n",
      "\n",
      "Day 6: Nha Trang\n",
      "* Fly from Danang to Nha Trang and check into the hotel.\n",
      "* Spend the day relaxing on the beach or exploring nearby attractions such as the Po Nagar Cham Towers and Long Son Pagoda.\n",
      "* Enjoy dinner at a local seafood restaurant.\n",
      "\n",
      "Day 7: Phong Nha-Ke Bang National Park\n",
      "* Drive from Nha Trang to Phong Nha-Ke Bang National Park.\n",
      "* Spend the day exploring the park's stunning limestone caves, such as the Dark Cave and Paradise Cave.\n",
      "* Enjoy dinner at a local restaurant.\n",
      "\n",
      "Day 8: Hue\n",
      "* Drive from Phong Nha to Hue.\n",
      "* Check into the hotel and spend the afternoon exploring this historic city.\n",
      "* Visit the Imperial City, Thien Mu Pagoda, and Dong Ba Market.\n",
      "\n",
      "Day 9: Hue and Beach Relaxation\n",
      "* Spend the day relaxing on the beach or exploring nearby attractions such as the Minh Mang Tomb and the Perfume River.\n",
      "* Enjoy a traditional Vietnamese tea ceremony.\n",
      "\n",
      "Day 10: Departure from Da Nang\n",
      "* Return to Da Nang airport for your flight home.\n",
      "This travel itinerary offers a mix of adventure, cultural exploration, and relaxation experiences in Vietnam, providing a memorable trip for you and your friends.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "prompt = \"Make a travel plan for a exciting experience in Vietnam with friends including various activites and relaxing experience\"\n",
    "inputs = tokenizer2(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "\n",
    "response = tokenizer2.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T05:49:37.430865Z",
     "iopub.status.busy": "2025-05-24T05:49:37.430318Z",
     "iopub.status.idle": "2025-05-24T05:50:06.053636Z",
     "shell.execute_reply": "2025-05-24T05:50:06.052985Z",
     "shell.execute_reply.started": "2025-05-24T05:49:37.430843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make me a solo trip in a beach area. февраль [].\n",
      "The beach area I have chosen for your solo trip is Bali, Indonesia. This island is known for its beautiful beaches, rich culture, and relaxing atmosphere. Here are some suggestions for activities to do during your solo travel:\n",
      "1. Explore the local markets: Visit the traditional markets of Bali, such as Pasar Badung or Pasar Kumbasari, to experience the vibrant colors and scents of the island's unique culture. You can shop for souvenirs, try local foods, and interact with the friendly locals.\n",
      "2. Take a yoga class: Bali is famous for its yoga retreats, and there are numerous studios throughout the island where you can take a class. Not only will this help you relax, but it will also provide an opportunity to meet other travelers and make new friends.\n",
      "3. Go on a surfing adventure: Bali is known for its excellent surfing conditions, and there are many surf schools located along the coast. If you're a beginner, don't worry – there are instructors available who will teach you how to surf. Even if you're not interested in surfing, you can still enjoy the beautiful ocean views and watch the surfers from the shore.\n",
      "4. Visit temples: Bali has many beautiful temples that are worth visiting. These temples offer a glimpse into the island's rich spiritual heritage and are often peaceful and serene places to spend time alone. Some popular temples include Tanah Lot Temple, Ulun Danu Beratan Temple, and Pura Tirtha Empul.\n",
      "5. Take a cooking class: Learn how to prepare delicious Balinese dishes by taking a cooking class. This activity will not only give you the opportunity to taste different flavors, but it will also provide an insight into the island's culinary culture.\n",
      "6. Relax at a spa: After a day of exploring and learning about the island, treat yourself to a relaxing spa treatment. There are numerous spas throughout Bali that offer various massages, facials, and other treatments. Spend some time unwinding and rejuvenating while enjoying the beautiful surroundings.\n",
      "7. Explore nature reserves: Bali has several nature reserves that are home to exotic flora and fauna. Take a guided tour through these areas to learn more about the island's unique ecosystem and spot some of the local wildlife.\n",
      "8. Take a sunset walk: End your day by taking a leisurely stroll along the beachfront or a scenic trail overlooking the ocean. As the sun sets, the sky transforms into a kaleidoscope of colors, making for a truly unforgettable experience.\n"
     ]
    }
   ],
   "source": [
    "model2.eval()\n",
    "\n",
    "prompt = \"make me a solo trip in a beach area\"\n",
    "inputs = tokenizer2(prompt, return_tensors=\"pt\").to(model2.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "\n",
    "response = tokenizer2.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T06:05:17.464312Z",
     "iopub.status.busy": "2025-05-24T06:05:17.463687Z",
     "iopub.status.idle": "2025-05-24T06:05:43.505161Z",
     "shell.execute_reply": "2025-05-24T06:05:43.504369Z",
     "shell.execute_reply.started": "2025-05-24T06:05:17.464287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to travel to relaxing destination with affordable accomodation and relaxing sightseeing activities. hopefully you can suggest some places that fit my criteria.\n",
      "Certainly! Based on your preferences, here are some suggestions for destinations that offer affordable accommodation and relaxing sightseeing activities:\n",
      "1. Bali, Indonesia: Bali is known as the \"Island of the Gods\" for its beautiful beaches, temples, and lush green landscapes. The island offers a range of accommodation options from budget-friendly guesthouses to luxury resorts. Some popular sightseeing activities include visiting the famous Tanah Lot Temple, exploring Ubud's art galleries, and relaxing on Kuta Beach. Prices vary depending on the season and location, but generally speaking, a budget of $50-$75 per day should cover most expenses.\n",
      "2. Thailand: Thailand is another popular destination for those seeking a relaxing vacation at an affordable price. The country is home to numerous beautiful beaches, ancient temples, and delicious street food. Affordable accommodation options include hostels and budget hotels, while sightseeing activities like visiting Ayutthaya Historical Park, hiking in Chiang Mai, or exploring Bangkok's Grand Palace are all within reach. A daily budget of $40-$60 should cover most expenses.\n",
      "3. Costa Rica: Costa Rica is a nature lover's paradise, with lush rainforests, stunning beaches, and abundant wildlife. Affordable accommodation options include eco-lodges and budget hotels, while sightseeing activities such as zip-lining through the jungle, rafting down the Reventazon River, or simply relaxing on the beach are all available. A daily budget of $60-$80 should cover most expenses.\n",
      "4. Vietnam: Vietnam is a great destination for those looking for a relaxing vacation with affordable prices. From the bustling streets of Hanoi and Ho Chi Minh City to the peaceful countryside and beautiful beaches, there's something for everyone. Budget accommodation options abound, while sightseeing activities like exploring the ancient city of Hoi An, visiting the Cu Chi Tunnels near Ho Chi Minh City, or simply enjoying a meal at a local restaurant are all within reach. A daily budget of $40-$60 should cover most expenses.\n",
      "I hope these suggestions help you plan your trip! Let me know if you have any other questions or if you need further assistance. \n"
     ]
    }
   ],
   "source": [
    "prompt = \"I want to travel to relaxing destination with affordable accomodation and relaxing sight\"\n",
    "inputs = tokenizer2(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.1\n",
    "    )\n",
    "\n",
    "response = tokenizer2.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T14:47:53.519707Z",
     "iopub.status.busy": "2025-06-12T14:47:53.519435Z",
     "iopub.status.idle": "2025-06-12T14:47:53.527734Z",
     "shell.execute_reply": "2025-06-12T14:47:53.526905Z",
     "shell.execute_reply.started": "2025-06-12T14:47:53.519686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,  8561,   263,  9850,  3814,   363,   263,  5566, 11407,  7271,\n",
       "           297, 18444,   411,  7875,  3704,  5164,  5039,  3246,   322, 26681,\n",
       "           292,  7271]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-24T07:16:48.260351Z",
     "iopub.status.busy": "2025-05-24T07:16:48.259575Z",
     "iopub.status.idle": "2025-05-24T07:16:48.263817Z",
     "shell.execute_reply": "2025-05-24T07:16:48.262968Z",
     "shell.execute_reply.started": "2025-05-24T07:16:48.260325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# CANT DO THIS CUZ PIPELINE DOESNT SUPPORT LORA + QUANTIZATION\n",
    "# from transformers import pipeline\n",
    "# pipe = pipeline(\"text-generation\", model=\"rakibulnahin/travel-chat-llama2-7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
